{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis - Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.display import Image, display\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import nltk\n",
    "#from nltk.tokenize import word_tokenize\n",
    "#from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "#import numpy as numpy\n",
    "import random\n",
    "#import pickle\n",
    "from collections import Counter\n",
    "import codecs\n",
    "import tensorflow as tf\n",
    "import np\n",
    "import time\n",
    "\n",
    "import os\n",
    "from os.path import join, exists\n",
    "\n",
    "import pandas as pd\n",
    "import pydot_ng as pydot\n",
    "import graphviz\n",
    "from ggplot import *\n",
    "\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Embedding, Dropout, Flatten, LSTM\n",
    "from keras.optimizers import RMSprop, Adam, SGD, Adagrad\n",
    "\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('wordnet')\n",
    "#totalLinesToRead = 100\n",
    "#lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data load\n",
    "\n",
    "The first step when building machine learning model is getting your data into the proper form to feed into the model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/twitter-train-pos', 'r') as f:\n",
    "    positive_train_txt = f.read()\n",
    "with open('./data/twitter-train-neg', 'r') as f:\n",
    "    negative_train_txt = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The positive data size: 22403729\n",
      "The negative data size: 22157551\n"
     ]
    }
   ],
   "source": [
    "print(\"The positive data size: {}\".format(len(positive_train_txt)))\n",
    "print(\"The negative data size: {}\".format(len(negative_train_txt)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic prediction\n",
    "Let's assume we will say to all data positive.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic/Benchmark Accuracy: 0.502762241121\n"
     ]
    }
   ],
   "source": [
    "print(\"Basic/Benchmark Accuracy: \" + str(float(len(positive_train_txt)) / (len(positive_train_txt) + len(negative_train_txt))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max word sentence: 0\n"
     ]
    }
   ],
   "source": [
    "print('Max word sentence: %d' % max_word_count_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Couple issues here. We seem to have one review with zero length. And, the maximum review length is way too many steps for our RNN. Let's truncate to 200 steps. For reviews shorter than 200, we'll pad with 0s. For reviews longer than 200, we can truncate them to the first 200 characters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turns out its the final review that has zero length. But that might not always be the case, so let's make it more general.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training, Validation, Test\n",
    "\n",
    "With our data in nice shape, we'll split it into training, validation, and test sets. Do not foget to shuffle it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-b213650b0b0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msplit_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msplit_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msplit_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msplit_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msplit_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'features' is not defined"
     ]
    }
   ],
   "source": [
    "split_idx = int(len(features)*0.8)\n",
    "train_x, val_x = features[:split_idx], features[split_idx:]\n",
    "train_y, val_y = labels[:split_idx], labels[split_idx:]\n",
    "\n",
    "test_idx = int(len(val_x)*0.5)\n",
    "val_x, test_x = val_x[:test_idx], val_x[test_idx:]\n",
    "val_y, test_y = val_y[:test_idx], val_y[test_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "batch_size = 20\n",
    "\n",
    "model = load_model('model_15_embedded_drop_0.1_twitter.h5')\n",
    "    \n",
    "score, acc = model.evaluate(test_x, test_y,\n",
    "                                batch_size=batch_size)\n",
    "print('  Test score:', score)\n",
    "print('  Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.figure(figsize=(14, 10))#, dpi=100)\n",
    "\n",
    "ax1 = plt.subplot2grid((3, 2), (0, 0))\n",
    "ax1.set_title('Training Accuracy')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.set_xlabel('Epochs')\n",
    "\n",
    "ax2 = plt.subplot2grid((3, 2), (1, 0))\n",
    "ax2.set_title('Training Loss')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.set_xlabel('Epochs')\n",
    "\n",
    "ax3 = plt.subplot2grid((3, 2), (0, 1))\n",
    "ax3.set_title('Validation Accuracy')\n",
    "ax3.set_ylabel('Accuracy')\n",
    "ax3.set_xlabel('Epochs')\n",
    "\n",
    "ax4 = plt.subplot2grid((3, 2), (1, 1))\n",
    "ax4.set_title('Validation Loss')\n",
    "ax4.set_ylabel('Loss')\n",
    "ax4.set_xlabel('Epochs')\n",
    "\n",
    "ax5 = plt.subplot2grid((3, 2), (2, 0), rowspan=1, colspan=2)\n",
    "ax5.set_title('Time')\n",
    "ax5.set_ylabel('Seconds')\n",
    "\n",
    "for mode, result in zip(models, results):\n",
    "    ax1.plot(result[0].epoch, result[0].history['acc'], label=mode)\n",
    "    ax2.plot(result[0].epoch, result[0].history['loss'], label=mode)\n",
    "    ax3.plot(result[0].epoch, result[0].history['val_acc'], label=mode)\n",
    "    ax4.plot(result[0].epoch, result[0].history['val_loss'], label=mode)\n",
    "    \n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "\n",
    "ax3.legend()\n",
    "ax4.legend()\n",
    "\n",
    "ax5.bar(np.arange(len(results)), [x[1] for x in results], tick_label = models.keys(), align='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
